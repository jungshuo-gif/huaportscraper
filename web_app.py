import streamlit as st
import pandas as pd
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from webdriver_manager.core.os_manager import ChromeType
import time
import re
import os
import xml.etree.ElementTree as ET
from datetime import datetime, timedelta, time as dt_time

# --- 1. åŸºç¤è¨­å®šèˆ‡æ™‚é–“å‡½å¼ ---
st.set_page_config(page_title="èŠ±è“®æ¸¯èˆ¹èˆ¶å³æ™‚æŸ¥è©¢", layout="wide")

def get_taiwan_time():
    """å–å¾—ç•¶å‰å°ç£æ™‚é–“"""
    return (datetime.utcnow() + timedelta(hours=8)).replace(second=0, microsecond=0)

def split_date_range(start, end):
    """å°‡é•·å€é–“æ‹†åˆ†ç‚ºå¤šå€‹ 7 å¤©å…§çš„å€æ®µ"""
    segments = []
    current_start = start
    while current_start < end:
        # çµæŸé»ç‚ºé–‹å§‹é» + 7å¤©ï¼Œä½†ä¸è¶…éæœ€çµ‚çµæŸæ™‚é–“
        current_end = min(current_start + timedelta(days=7), end)
        segments.append((current_start, current_end))
        # ä¸‹ä¸€æ®µå¾çµæŸé»å¾Œ 1 åˆ†é˜é–‹å§‹ï¼Œé¿å…è³‡æ–™é‡ç–Š
        current_start = current_end + timedelta(minutes=1)
    return segments
    
# --- 2. åˆå§‹åŒ–èˆ‡é€£å‹•é‚è¼¯ ---

# æª¢æŸ¥æ˜¯å¦ç‚ºã€Œç¬¬ä¸€æ¬¡é€²å…¥ç¶²é ã€
if 'first_run' not in st.session_state:
    st.session_state.first_run = True      # æ¨™è¨˜å·²ç¶“åŸ·è¡Œéåˆæ¬¡è¼‰å…¥
    st.session_state.trigger_search = True # å¼·åˆ¶å•Ÿå‹•ç¬¬ä¸€æ¬¡æŸ¥è©¢

# (åŸæœ¬å°±æœ‰çš„å…¶ä»–åˆå§‹åŒ–)
if 'last_option' not in st.session_state:
    st.session_state.last_option = "æœªä¾† 24H"

def update_time_fields():
    """å–®é¸éˆ•æ”¹è®Šæ™‚ï¼Œå³æ™‚æ›´æ–°è¼¸å…¥æ¡†å…§å®¹"""
    now = get_taiwan_time()
    opt = st.session_state.temp_option
    new_sd, new_st = now.date(), now.time()
    new_ed, new_et = now.date(), now.time()

    if opt == "æœªä¾† 24H":
        f = now + timedelta(hours=24); new_ed, new_et = f.date(), f.time()
    elif opt == "æœªä¾† 3 æ—¥":
        f = now + timedelta(hours=72); new_ed, new_et = f.date(), f.time()
    elif opt == "å‰ 7 æ—¥":
        p = now - timedelta(days=7); new_sd, new_st = p.date(), dt_time(0, 0)
    elif opt == "æœ¬æœˆæ•´æœˆ":
        # æ­¤è™•ä¸å†å— 7 å¤©é™åˆ¶ï¼Œç›´æ¥è¨­ç‚ºæœˆåˆåˆ°ä»Šå¤©
        first_day = now.replace(day=1, hour=0, minute=0)
        new_sd, new_st = first_day.date(), first_day.time()

    st.session_state.sd_key = new_sd
    st.session_state.st_key = new_st
    st.session_state.ed_key = new_ed
    st.session_state.et_key = new_et
    
    if opt != "æ‰‹å‹•èª¿æ•´":
        st.session_state.trigger_search = True

# --- æ ¸å¿ƒçˆ¬èŸ²é‚è¼¯ ---
def run_scraper(start_time, end_time):
    download_dir = os.path.join(os.getcwd(), "temp_downloads")
    if not os.path.exists(download_dir):
        os.makedirs(download_dir)
    
    # æ¸…ç†èˆŠæª”
    for f in os.listdir(download_dir):
        try: os.remove(os.path.join(download_dir, f))
        except: pass

    status_text = st.empty()
    status_text.info("ğŸš€ æ­£åœ¨å•Ÿå‹•é›²ç«¯ç€è¦½å™¨æ ¸å¿ƒ...")
    
    driver = None
    try:
        options = webdriver.ChromeOptions()
        # --- é›²ç«¯ç’°å¢ƒå¿…è¦è¨­å®š (Headless) ---
        options.add_argument("--headless") 
        options.add_argument("--no-sandbox")
        options.add_argument("--disable-dev-shm-usage")
        options.add_argument("--disable-gpu")
        options.add_argument("--window-size=1920,1080")
        options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
        
        prefs = {
            "download.default_directory": download_dir,
            "download.prompt_for_download": False,
            "download.directory_upgrade": True,
            "safebrowsing.enabled": True
        }
        options.add_experimental_option("prefs", prefs)
        
        # --- é—œéµï¼šåœ¨ Linux ç’°å¢ƒä½¿ç”¨ Chromium ---
        # é€™è£¡æŒ‡å®šä½¿ç”¨ ChromeType.CHROMIUMï¼Œé€™æ˜¯ Streamlit Cloud æ”¯æ´çš„ç‰ˆæœ¬
        service = Service(ChromeDriverManager(chrome_type=ChromeType.CHROMIUM).install())
        driver = webdriver.Chrome(service=service, options=options)
        
        # é˜²åµæ¸¬è¨­å®š
        driver.execute_cdp_cmd("Page.addScriptToEvaluateOnNewDocument", {
            "source": """Object.defineProperty(navigator, 'webdriver', {get: () => undefined})"""
        })
        driver.execute_cdp_cmd('Page.setDownloadBehavior', {'behavior': 'allow', 'downloadPath': download_dir})
        
        status_text.info(f"ğŸ”— é€£ç·šä¸­...")
        driver.get("https://tpnet.twport.com.tw/IFAWeb/Function?_RedirUrl=/IFAWeb/Reports/HistoryPortShipList")
        
        wait = WebDriverWait(driver, 20)
        
        # --- åˆ‡æ› iFrame ---
        iframes = driver.find_elements(By.TAG_NAME, "iframe")
        if iframes: driver.switch_to.frame(0)
        time.sleep(1)
        
        # --- é»æ“ŠèŠ±è“®æ¸¯ ---
        try:
            hualien_tab = wait.until(EC.element_to_be_clickable((By.XPATH, "//*[contains(text(),'èŠ±è“®æ¸¯')]")))
            driver.execute_script("arguments[0].click();", hualien_tab)
            time.sleep(1)
        except: pass

        # --- è¼¸å…¥æ—¥æœŸ ---
        str_start = start_time.strftime("%Y/%m/%d %H:%M") 
        str_end = end_time.strftime("%Y/%m/%d %H:%M")
        
        all_inputs = driver.find_elements(By.TAG_NAME, "input")
        text_inputs = [i for i in all_inputs if i.get_attribute('type') in ['text', '']]
        target_inputs = [inp for inp in text_inputs if inp.get_attribute("value") and "20" in inp.get_attribute("value")]
        
        if len(target_inputs) >= 2:
            driver.execute_script(f"arguments[0].value = '{str_start}'; arguments[0].dispatchEvent(new Event('change'));", target_inputs[0])
            driver.execute_script(f"arguments[0].value = '{str_end}'; arguments[0].dispatchEvent(new Event('change'));", target_inputs[1])
        
        # --- é»æ“ŠæŸ¥è©¢ ---
        status_text.info("ğŸ” æŸ¥è©¢è³‡æ–™ä¸­...")
        query_btn = driver.find_element(By.XPATH, "//*[contains(@value,'Query') or contains(@value,'æŸ¥è©¢')]")
        driver.execute_script("arguments[0].click();", query_btn)
        time.sleep(5) 
        
        # --- ä¸‹è¼‰ XML ---
        status_text.info("ğŸ“¥ å˜—è©¦ä¸‹è¼‰å ±è¡¨...")
        try:
            driver.switch_to.default_content()
            driver.switch_to.frame(0)
        except: pass
        
        clicked = False
        btns = driver.find_elements(By.XPATH, "//*[contains(text(), 'XML') or contains(@value, 'XML')]")
        for btn in btns:
            if btn.is_displayed():
                driver.execute_script("arguments[0].click();", btn)
                clicked = True
                break
        
        if not clicked:
            export_btns = driver.find_elements(By.XPATH, "//a[contains(@title, 'Export')]")
            if not export_btns: export_btns = driver.find_elements(By.XPATH, "//img[contains(@alt, 'Export')]/..")
            if export_btns:
                driver.execute_script("arguments[0].click();", export_btns[0])
                time.sleep(1)
                xml_items = driver.find_elements(By.XPATH, "//a[contains(text(), 'XML')]")
                if xml_items:
                    driver.execute_script("arguments[0].click();", xml_items[0])

        # --- ç­‰å¾…æª”æ¡ˆ ---
        downloaded_file = None
        for _ in range(15):
            time.sleep(1)
            files = [f for f in os.listdir(download_dir) if f.endswith('.xml')]
            if files:
                downloaded_file = os.path.join(download_dir, files[0])
                break
        
        if not downloaded_file:
            raise Exception("æœªåµæ¸¬åˆ°ä¸‹è¼‰æª”æ¡ˆ")
            
        status_text.info("âš™ï¸ è§£æè³‡æ–™ (Big5)...")
        
        with open(downloaded_file, 'r', encoding='big5', errors='replace') as f:
            xml_content = f.read().replace('encoding="BIG5"', '').replace('encoding="big5"', '')
            
        root = ET.fromstring(xml_content)
        parsed_data = []
        
        for ship in root.findall('SHIP'):
            try:
                cname = ship.find('VESSEL_CNAME').text or ""
                
                gt_str = ship.find('GROSS_TOA').text or "0"
                try: gt = int(round(float(gt_str)))
                except: gt = 0
                
                if gt <= 500 and "æ±æ¹§8è™Ÿ" not in cname: continue
                
                pilot_time_raw = ship.find('PILOT_EXP_TM').text or ""
                date_display, time_display = "", ""
                if len(pilot_time_raw) >= 12:
                    date_display = f"{pilot_time_raw[4:6]}/{pilot_time_raw[6:8]}"
                    time_display = f"{pilot_time_raw[8:10]}:{pilot_time_raw[10:12]}"
                
                raw_agent = ship.find('PBG_NAME').text or ""
                agent_full = raw_agent.strip()
                if "å°ç£èˆ¹é‹" in agent_full: agent_name = "å°èˆ¹"
                elif "æµ·è»" in agent_full: agent_name = "æµ·è»"
                else: agent_name = agent_full[:2] 
                
                loa_str = ship.find('LOA').text or "0"
                try: loa = int(round(float(loa_str)))
                except: loa = 0

                parsed_data.append({
                    "æ—¥æœŸ": date_display,
                    "æ™‚é–“": time_display,
                    "ç‹€æ…‹": ship.find('SP_STS').text,
                    "ç¢¼é ­": ship.find('WHARF_CODE').text,
                    "ä¸­æ–‡èˆ¹å": cname,
                    "é•·åº¦(m)": loa,
                    "è‹±æ–‡èˆ¹å": ship.find('VESSEL_ENAME').text,
                    "ä»£ç†è¡Œ": agent_name,  
                    "ç¸½å™¸ä½": gt,
                    "å‰ä¸€æ¸¯": ship.find('BEFORE_PORT').text,
                    "ä¸‹ä¸€æ¸¯": ship.find('NEXT_PORT').text,
                })
            except: continue
        
        status_text.empty()
        return pd.DataFrame(parsed_data)

    except Exception as e:
        status_text.error(f"âŒ éŒ¯èª¤: {str(e)}")
        return None
    finally:
        if driver: driver.quit()

# --- é¡¯ç¤ºçµæœ ---
if run_btn:
    if start_dt > end_dt:
        st.error("âŒ é–‹å§‹æ™‚é–“ä¸èƒ½æ™šæ–¼çµæŸæ™‚é–“")
    else:
        df = run_scraper(start_dt, end_dt)
        if df is not None and not df.empty:
            df = df.sort_values(by=["æ—¥æœŸ", "æ™‚é–“"])
            
            st.success(f"âœ… æŸ¥è©¢å®Œæˆï¼({start_dt.strftime('%m/%d %H:%M')} - {end_dt.strftime('%m/%d %H:%M')})")
            
            cols = ["æ—¥æœŸ", "æ™‚é–“", "ç‹€æ…‹", "ç¢¼é ­", "ä¸­æ–‡èˆ¹å", "é•·åº¦(m)", "è‹±æ–‡èˆ¹å", "ç¸½å™¸ä½", "å‰ä¸€æ¸¯", "ä¸‹ä¸€æ¸¯", "ä»£ç†è¡Œ"]
            final_cols = [c for c in cols if c in df.columns]
            
            st.dataframe(
                df[final_cols], 
                use_container_width=True, 
                hide_index=True
            )
            
            csv = df.to_csv(index=False).encode('utf-8-sig')
            st.download_button(
                label="ğŸ“¥ ä¸‹è¼‰å ±è¡¨",
                data=csv,
                file_name=f"èŠ±è“®æ¸¯_{start_dt.strftime('%Y%m%d_%H%M')}.csv",
                mime="text/csv",
                type="primary",
                use_container_width=True
            )
        elif df is not None:
            st.warning("âš ï¸ æ­¤å€é–“æŸ¥ç„¡ç¬¦åˆæ¢ä»¶çš„èˆ¹èˆ¶è³‡æ–™")


