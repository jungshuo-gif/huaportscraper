import streamlit as st
import pandas as pd
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from webdriver_manager.core.os_manager import ChromeType
from selenium.webdriver.support.ui import Select
import time
import re
import os
import xml.etree.ElementTree as ET
from datetime import datetime, timedelta, time as dt_time

# --- 1. åŸºç¤è¨­å®š ---
st.set_page_config(page_title="èŠ±è“®æ¸¯èˆ¹èˆ¶å³æ™‚æŸ¥è©¢", layout="wide")

def get_taiwan_time():
    """å–å¾—ç•¶å‰å°ç£æ™‚é–“ (æŠ¹é™¤ç§’æ•¸)"""
    return (datetime.utcnow() + timedelta(hours=8)).replace(second=0, microsecond=0)

def split_date_range(start, end):
    """å°‡é•·å€é–“æ‹†åˆ†ç‚ºå¤šå€‹ 7 å¤©å…§çš„å€æ®µ"""
    segments = []
    curr_start = start
    while curr_start < end:
        curr_end = min(curr_start + timedelta(days=7), end)
        segments.append((curr_start, curr_end))
        curr_start = curr_end + timedelta(seconds=1)
    return segments

# --- 2. åˆå§‹åŒ– Session State ---
if 'trigger_search' not in st.session_state:
    st.session_state.trigger_search = False 
if 'expander_state' not in st.session_state:
    st.session_state.expander_state = False 

# --- 3. UI é€£å‹•å›èª¿ ---
def on_ui_change():
    now = get_taiwan_time()
    opt = st.session_state.ui_option
    
    sd, st_val = now.date(), now.time()
    ed, et_val = now.date(), now.time()

    if opt == "æœªä¾† 24H":
        f = now + timedelta(hours=24); ed, et_val = f.date(), f.time()
        st.session_state.expander_state = False
    elif opt == "æœªä¾† 3 æ—¥":
        f = now + timedelta(hours=72); ed, et_val = f.date(), f.time()
        st.session_state.expander_state = False
    elif opt == "å‰ 7 æ—¥":
        p = now - timedelta(days=7); sd, st_val = p.date(), dt_time(0, 0)
        st.session_state.expander_state = False
    elif opt == "æœ¬æœˆæ•´æœˆ":
        first_day = now.replace(day=1, hour=0, minute=0)
        sd, st_val = first_day.date(), first_day.time()
        st.session_state.expander_state = False

    st.session_state.sd_key = sd
    st.session_state.st_key = st_val
    st.session_state.ed_key = ed
    st.session_state.et_key = et_val
    
    st.session_state.trigger_search = True

# --- 4. æ ¸å¿ƒçˆ¬èŸ²å‡½æ•¸ ---
def run_scraper_segment(start_time, end_time, step_text=""):
    download_dir = os.path.join(os.getcwd(), "temp_downloads")
    if not os.path.exists(download_dir): os.makedirs(download_dir)
    for f in os.listdir(download_dir):
        try: os.remove(os.path.join(download_dir, f))
        except: pass

    driver = None
    with st.status(f"ğŸš¢ æŸ¥è©¢ä¸­ï¼Œè«‹ç­‰å€™ç´„10ç§’ {step_text}...", expanded=True) as status:
        try:
            options = webdriver.ChromeOptions()
            options.add_argument("--headless=new")
            options.add_argument("--no-sandbox")
            options.add_argument("--disable-dev-shm-usage")
            options.add_experimental_option("prefs", {"download.default_directory": download_dir})
            service = Service(ChromeDriverManager(chrome_type=ChromeType.CHROMIUM).install())
            driver = webdriver.Chrome(service=service, options=options)
            driver.execute_cdp_cmd('Page.setDownloadBehavior', {'behavior': 'allow', 'downloadPath': download_dir})
            driver.get("https://tpnet.twport.com.tw/IFAWeb/Function?_RedirUrl=/IFAWeb/Reports/HistoryPortShipList")
            wait = WebDriverWait(driver, 20)
            if driver.find_elements(By.TAG_NAME, "iframe"): driver.switch_to.frame(0)
            
            h_tab = wait.until(EC.element_to_be_clickable((By.XPATH, "//*[contains(text(),'èŠ±è“®æ¸¯')]")))
            driver.execute_script("arguments[0].click();", h_tab)

            v_s, v_e = start_time.strftime("%Y/%m/%d %H:%M"), end_time.strftime("%Y/%m/%d %H:%M")
            status.write(f"ğŸ“ å¡«å¯«å€é–“: {v_s} ~ {v_e}")
            inps = driver.find_elements(By.TAG_NAME, "input")
            d_inps = [i for i in inps if i.get_attribute("value") and i.get_attribute("value").startswith("20")]
            if len(d_inps) >= 2:
                driver.execute_script(f"arguments[0].value = '{v_s}'; arguments[0].dispatchEvent(new Event('change'));", d_inps[0])
                driver.execute_script(f"arguments[0].value = '{v_e}'; arguments[0].dispatchEvent(new Event('change'));", d_inps[1])
            
            checked_boxes = driver.find_elements(By.CSS_SELECTOR, "input[type='checkbox']:checked")
            for cb in checked_boxes: driver.execute_script("arguments[0].click();", cb)
            
            try:
                sort_sel = driver.find_element(By.XPATH, "//*[contains(text(),'Ordering by')]/following::select[1]")
                Select(sort_sel).select_by_index(1)
            except: pass

            btn = driver.find_element(By.XPATH, "//*[contains(@value,'Query') or contains(@value,'æŸ¥è©¢')]")
            driver.execute_script("arguments[0].click();", btn)
            time.sleep(4)
            
            xml_btns = driver.find_elements(By.XPATH, "//*[contains(text(), 'XML') or contains(@value, 'XML')]")
            if xml_btns: driver.execute_script("arguments[0].click();", xml_btns[0])
            
            downloaded_file = None
            for _ in range(15):
                time.sleep(1)
                xml_fs = [os.path.join(download_dir, f) for f in os.listdir(download_dir) if f.lower().endswith('.xml')]
                if xml_fs:
                    downloaded_file = max(xml_fs, key=os.path.getmtime)
                    break
            
            if not downloaded_file: return pd.DataFrame()

            with open(downloaded_file, 'r', encoding='big5', errors='replace') as f:
                content = f.read().replace('encoding="BIG5"', '').replace('encoding="big5"', '')
            
            root = ET.fromstring(content)
            parsed = []
            for ship in root.findall('SHIP'):
                gt_n = ship.find('GROSS_TOA')
                gt = int(round(float(gt_n.text))) if gt_n is not None and gt_n.text else 0
                if gt < 500 : continue

                w_n = ship.find('WHARF_CODE')
                raw_w = w_n.text if w_n is not None else ""
                w_label = f"{int(re.search(r'(\d+)', raw_w).group(1)):02d}è™Ÿ" if raw_w and re.search(r'(\d+)', raw_w) else raw_w

                t_n = ship.find('PILOT_EXP_TM')
                raw_t = t_n.text if t_n is not None else ""
                d_s, t_s = "æœªæ’å®š", "æœªæ’å®š"
                if len(raw_t) >= 12: d_s, t_s = f"{raw_t[4:6]}/{raw_t[6:8]}", f"{raw_t[8:10]}:{raw_t[10:12]}"

                parsed.append({
                    "æ—¥æœŸ": d_s, "æ™‚é–“": t_s, "ç‹€æ…‹": ship.find('SP_STS').text if ship.find('SP_STS') is not None else "",
                    "ç¢¼é ­": w_label, "ä¸­æ–‡èˆ¹å": ship.find('VESSEL_CNAME').text or "",
                    "é•·åº¦(m)": int(round(float(ship.find('LOA').text))) if ship.find('LOA') is not None else 0,
                    "è‹±æ–‡èˆ¹å": ship.find('VESSEL_ENAME').text if ship.find('VESSEL_ENAME') is not None else "",
                    "ç¸½å™¸ä½": gt, "å‰ä¸€æ¸¯": ship.find('BEFORE_PORT').text if ship.find('BEFORE_PORT') is not None else "",
                    "ä¸‹ä¸€æ¸¯": ship.find('NEXT_PORT').text if ship.find('NEXT_PORT') is not None else "",
                    "ä»£ç†è¡Œ": (ship.find('PBG_NAME').text or "")[:2]
                })
            status.update(label="âœ… æŸ¥è©¢å®Œæˆ", state="complete", expanded=False)
            return pd.DataFrame(parsed)
        except Exception as e:
            st.error(f"âŒ éŒ¯èª¤: {e}")
            return pd.DataFrame()
        finally:
            if driver: driver.quit()

# --- 4.5 è·¨ Session å…¨åŸŸå…±äº«å¿«å– ---
# ä¿®æ­£é»ï¼šåŠ å…¥ show_spinner=False ä»¥éš±è—éé æœŸçš„ "Running..." ç³»çµ±æ–‡å­—
@st.cache_data(ttl=1200, show_spinner=False)
def get_shared_24h_data():
    now_tw = get_taiwan_time()
    f24 = now_tw + timedelta(hours=24)
    df = run_scraper_segment(now_tw, f24, "(å…¨åŸŸè‡ªå‹•åŒæ­¥)")
    if not df.empty:
        cols = ["æ—¥æœŸ", "æ™‚é–“", "ç‹€æ…‹", "ç¢¼é ­", "ä¸­æ–‡èˆ¹å", "é•·åº¦(m)", "è‹±æ–‡èˆ¹å", "ç¸½å™¸ä½", "å‰ä¸€æ¸¯", "ä¸‹ä¸€æ¸¯", "ä»£ç†è¡Œ"]
        return df[cols].drop_duplicates().sort_values(by=["æ—¥æœŸ", "æ™‚é–“"]), get_taiwan_time()
    return None, None

# --- 5. UI ä»‹é¢ ---
st.markdown(
    """<h3 style='text-align: left; font-size: 24px; margin-bottom: 20px;'>ğŸš¢ èŠ±è“®æ¸¯èˆ¹èˆ¶å‹•æ…‹æŸ¥è©¢</h3>""", 
    unsafe_allow_html=True
)

now_init = get_taiwan_time()
f24_init = now_init + timedelta(hours=24)

st.radio(
    "â±ï¸ **é è¨­é¡¯ç¤ºæœªä¾†24Hå‹•æ…‹(æ¯20åˆ†é˜è‡ªå‹•æ›´æ–°)ã€‚é»é¸æŒ‰éˆ•å¯å³æ™‚é‡æ–°æŸ¥è©¢ã€‚**",
    ["æœªä¾† 24H", "æœªä¾† 3 æ—¥", "å‰ 7 æ—¥", "æœ¬æœˆæ•´æœˆ"],
    key="ui_option",
    on_change=on_ui_change,
    horizontal=True
)

# æ‘ºç–Šé¸å–®
with st.expander("æ›´æ”¹æŸ¥è©¢æ™‚æ®µ", expanded=st.session_state.expander_state):
    c1, c2 = st.columns(2)
    with c1:
        sd_in = st.date_input("é–‹å§‹æ—¥æœŸ", key="sd_key", value=now_init.date())
        st_in = st.time_input("é–‹å§‹æ™‚é–“", key="st_key", value=now_init.time(), label_visibility="collapsed")
    with c2:
        ed_in = st.date_input("çµæŸæ—¥æœŸ", key="ed_key", value=f24_init.date())
        et_in = st.time_input("çµæŸæ™‚é–“", key="et_key", value=f24_init.time(), label_visibility="collapsed")

start_dt = datetime.combine(sd_in, st_in)
end_dt = datetime.combine(ed_in, et_in)

# æŒ‰éˆ•å€åŸŸ (å›ºå®šåœ¨æ™‚æ®µé¸å–®ä¸‹æ–¹)
st.write("") 
if st.button("ğŸš€ é–‹å§‹æŸ¥è©¢", type="primary", use_container_width=True):
    st.session_state.trigger_search = True
    # å¦‚æœæ˜¯æŸ¥è©¢ã€Œæœªä¾†24Hã€ï¼Œä¸æ¸…é™¤å¿«å–ï¼Œè€Œæ˜¯è®“æ‰‹å‹•æŸ¥è©¢çš„çµæœæ›´æ–°å¿«å–
    if st.session_state.ui_option != "æœªä¾† 24H":
        st.cache_data.clear()

# --- 6. åŸ·è¡Œé‚è¼¯ ---

# ğŸ”„ è‡ªå‹•æ›´æ–°æ©Ÿåˆ¶ï¼šæ¯20åˆ†é˜å¼·åˆ¶é‡æ–°æ•´ç†é é¢
if 'last_auto_refresh' not in st.session_state:
    st.session_state.last_auto_refresh = time.time()

if time.time() - st.session_state.last_auto_refresh > 1200:  # 1200ç§’ = 20åˆ†é˜
    st.session_state.last_auto_refresh = time.time()
    st.cache_data.clear()  # æ¸…é™¤å¿«å–ç¢ºä¿ç²å–æœ€æ–°è³‡æ–™
    st.rerun()

# æƒ…æ³ Aï¼šè®€å–å…¨åŸŸå¿«å–æ¨¡å¼ (è‡ªå‹•åŒæ­¥)
if st.session_state.ui_option == "æœªä¾† 24H" and not st.session_state.trigger_search:
    placeholder_status = st.empty()
    
    with placeholder_status.container():
        shared_df, update_time = get_shared_24h_data()
    
    # è³‡æ–™å–å¾—å¾Œï¼Œæ¸…ç©ºã€ŒæŸ¥è©¢ä¸­ã€çš„æç¤ºï¼Œåªä¿ç•™çµæœ
    placeholder_status.empty()
    
    if shared_df is not None:
        st.success(f"âš¡ é¡¯ç¤ºå…¨åŸŸåŒæ­¥è³‡æ–™ (æ›´æ–°æ™‚é–“: {update_time.strftime('%H:%M')})")
        st.dataframe(shared_df, use_container_width=True, hide_index=True)
        csv_shared = shared_df.to_csv(index=False).encode('utf-8-sig')
        st.download_button("ğŸ“¥ ä¸‹è¼‰å®Œæ•´å ±è¡¨", csv_shared, "Report_Shared.csv", use_container_width=True, key="dl_shared")
        st.stop() 

# æƒ…æ³ Cï¼šåŸ·è¡Œæ‰‹å‹•çˆ¬èŸ²é‚è¼¯ (æ‰‹å‹•æ¨¡å¼å‰‡ä¿ç•™é€²åº¦æ¢è®“ä½¿ç”¨è€…ç¢ºèªå®Œæˆ)
if st.session_state.trigger_search:
    st.session_state.trigger_search = False
    
    # ğŸ”¥ ç‰¹æ®Šè™•ç†ï¼šå¦‚æœæ˜¯æŸ¥è©¢ã€Œæœªä¾†24Hã€ï¼Œç›´æ¥æ›´æ–°å…¨åŸŸå¿«å–
    if st.session_state.ui_option == "æœªä¾† 24H":
        # æ¸…é™¤èˆŠå¿«å–
        st.cache_data.clear()
        
        # ğŸ¯ ç›´æ¥å‘¼å«å¿«å–å‡½æ•¸ï¼ˆåªæœƒåŸ·è¡Œä¸€æ¬¡çˆ¬èŸ²ï¼‰
        shared_df, update_time = get_shared_24h_data()
        
        if shared_df is not None:
            st.success(f"ğŸŠ æŸ¥è©¢å®Œæˆï¼å·²æ›´æ–°å…¨åŸŸå¿«å–ï¼Œå…± {len(shared_df)} ç­†è³‡æ–™ã€‚")
            st.dataframe(shared_df, use_container_width=True, hide_index=True)
            csv_manual = shared_df.to_csv(index=False).encode('utf-8-sig')
            st.download_button("ğŸ“¥ ä¸‹è¼‰å®Œæ•´å ±è¡¨", csv_manual, "Report_Shared.csv", use_container_width=True, key="dl_manual_24h")
        else:
            st.warning("âš ï¸ è©²å€é–“æŸ¥ç„¡ç¬¦åˆæ¢ä»¶çš„èˆ¹èˆ¶è³‡æ–™ã€‚")
        
        st.stop()  # å®Œæˆå¾Œåœæ­¢ï¼Œé¿å…åŸ·è¡Œå¾ŒçºŒé‚è¼¯
    
    # ä¸€èˆ¬æƒ…æ³ï¼šè™•ç†å…¶ä»–æ™‚æ®µçš„æŸ¥è©¢
    date_segments = split_date_range(start_dt, end_dt)
    all_dfs = []
    
    for i, (seg_s, seg_e) in enumerate(date_segments):
        df_seg = run_scraper_segment(seg_s, seg_e, f"({i+1}/{len(date_segments)})")
        if not df_seg.empty:
            all_dfs.append(df_seg)
    
    if all_dfs:
        final_df = pd.concat(all_dfs).drop_duplicates().sort_values(by=["æ—¥æœŸ", "æ™‚é–“"])
        cols = ["æ—¥æœŸ", "æ™‚é–“", "ç‹€æ…‹", "ç¢¼é ­", "ä¸­æ–‡èˆ¹å", "é•·åº¦(m)", "è‹±æ–‡èˆ¹å", "ç¸½å™¸ä½", "å‰ä¸€æ¸¯", "ä¸‹ä¸€æ¸¯", "ä»£ç†è¡Œ"]
        final_df = final_df[cols]
        st.success(f"ğŸŠ æŸ¥è©¢å®Œæˆï¼å…±ç²å– {len(final_df)} ç­†è³‡æ–™ã€‚")
        st.dataframe(final_df, use_container_width=True, hide_index=True)
        csv_manual = final_df.to_csv(index=False).encode('utf-8-sig')
        st.download_button("ğŸ“¥ ä¸‹è¼‰å®Œæ•´å ±è¡¨", csv_manual, f"Report_{start_dt.strftime('%m%d')}.csv", use_container_width=True, key="dl_manual")
    else:
        st.warning("âš ï¸ è©²å€é–“æŸ¥ç„¡ç¬¦åˆæ¢ä»¶çš„èˆ¹èˆ¶è³‡æ–™ã€‚")
